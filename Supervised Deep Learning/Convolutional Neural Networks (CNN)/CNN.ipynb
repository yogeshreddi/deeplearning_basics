{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification using convolutional nueral networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,..., activation=\"relu\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8002 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2699s 337ms/step - loss: 0.3930 - accuracy: 0.8149 - val_loss: 0.5835 - val_accuracy: 0.7555\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2421s 303ms/step - loss: 0.1620 - accuracy: 0.9374 - val_loss: 0.5518 - val_accuracy: 0.7677\n",
      "Epoch 3/25\n",
      "5563/8000 [===================>..........] - ETA: 18:21 - loss: 0.1070 - accuracy: 0.9603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py:616: UserWarning: The input 165 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 24564s 3s/step - loss: 0.1009 - accuracy: 0.9629 - val_loss: 1.0124 - val_accuracy: 0.7615\n",
      "Epoch 4/25\n",
      "2468/8000 [========>.....................] - ETA: 26:01 - loss: 0.0830 - accuracy: 0.9710"
     ]
    }
   ],
   "source": [
    "# intializing CNN\n",
    "imageClassifier = Sequential()\n",
    "\n",
    "# step 1 of CNN is adding convolution layer - convolving our images with feature extracter matrix \n",
    "imageClassifier.add(Conv2D(32,3,3,input_shape = (128,128,3),activation = 'relu'))\n",
    "\n",
    "# step 2 of CNN is adding a pooling layer\n",
    "imageClassifier.add(MaxPooling2D(pool_size = (2,2),strides = 2))\n",
    "\n",
    "# step 3 of a CNN is adding a flattening layer\n",
    "imageClassifier.add(Flatten())\n",
    "\n",
    "# step 4 in CNN is to add hidden layers\n",
    "imageClassifier.add(Dense(units = 128,activation = 'relu'))\n",
    "imageClassifier.add(Dense(units = 128,activation = 'relu'))\n",
    "imageClassifier.add(Dense(units = 1 ,activation = 'sigmoid'))\n",
    "\n",
    "#step 5 in CNN is to compile our CNN layers\n",
    "imageClassifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# step 6 in CNN is to fit the model on images\n",
    "\"\"\" \n",
    "we do image aggumentation to reduce overfitting by enriching our dataset without adding more data images,\n",
    "rather by looking at the available images differently everytime \n",
    " we use ImageDataGenerator for this oricess\n",
    "\"\"\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    'dataset/training_set',\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                                    'dataset/test_set',\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "imageClassifier.fit(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch=8000,\n",
    "                    epochs=25,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=2000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # look like our modeling is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
