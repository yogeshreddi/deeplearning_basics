{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating and Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# Male/Female\n",
    "le_X = LabelEncoder()\n",
    "X[:, 2] = le_X.fit_transform(X[:, 2])\n",
    "\n",
    "# Country column\n",
    "ct = ColumnTransformer([(\"Country\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "X = X[:,1:]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:63: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 1s 119us/step - loss: 0.4841 - accuracy: 0.7961\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4297 - accuracy: 0.7963\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4231 - accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4189 - accuracy: 0.8213\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4164 - accuracy: 0.8284\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4145 - accuracy: 0.8296\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4138 - accuracy: 0.8304\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4125 - accuracy: 0.8317\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.4115 - accuracy: 0.8313\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4105 - accuracy: 0.8339\n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4102 - accuracy: 0.8335\n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4093 - accuracy: 0.8321\n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.4087 - accuracy: 0.8332\n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4084 - accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4073 - accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4061 - accuracy: 0.8348\n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4068 - accuracy: 0.8357\n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4067 - accuracy: 0.8337\n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4063 - accuracy: 0.8347\n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4059 - accuracy: 0.8345\n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4058 - accuracy: 0.8339\n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4058 - accuracy: 0.8337\n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4048 - accuracy: 0.8340\n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4050 - accuracy: 0.8341\n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4049 - accuracy: 0.8341\n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4047 - accuracy: 0.8343\n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4043 - accuracy: 0.8348\n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4043 - accuracy: 0.8331\n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4043 - accuracy: 0.8348\n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4042 - accuracy: 0.8345\n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4040 - accuracy: 0.8337\n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4040 - accuracy: 0.8353\n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4039 - accuracy: 0.8357\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4034 - accuracy: 0.8339\n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4032 - accuracy: 0.8341\n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4033 - accuracy: 0.8347\n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4035 - accuracy: 0.8340\n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4027 - accuracy: 0.8332\n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4034 - accuracy: 0.8336\n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4026 - accuracy: 0.8353\n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4024 - accuracy: 0.8347\n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4028 - accuracy: 0.8332\n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.4019 - accuracy: 0.8351\n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4022 - accuracy: 0.8332\n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.4018 - accuracy: 0.8353\n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4018 - accuracy: 0.8328\n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4012 - accuracy: 0.8364\n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4013 - accuracy: 0.8344\n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.4008 - accuracy: 0.8347\n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4005 - accuracy: 0.8341\n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.4011 - accuracy: 0.8341\n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3999 - accuracy: 0.8380\n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.4002 - accuracy: 0.8349\n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3992 - accuracy: 0.8348\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.4002 - accuracy: 0.8343\n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3990 - accuracy: 0.8356\n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3986 - accuracy: 0.8361\n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3981 - accuracy: 0.8345\n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3988 - accuracy: 0.8347\n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3984 - accuracy: 0.8363\n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3980 - accuracy: 0.8353\n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3980 - accuracy: 0.8353\n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3979 - accuracy: 0.8349\n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.3978 - accuracy: 0.8357\n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3974 - accuracy: 0.8345\n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3977 - accuracy: 0.8357\n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3973 - accuracy: 0.8357\n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.3968 - accuracy: 0.8348\n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3965 - accuracy: 0.8347\n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3968 - accuracy: 0.8345\n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3969 - accuracy: 0.8336\n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3970 - accuracy: 0.8347\n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3965 - accuracy: 0.8349\n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.3964 - accuracy: 0.8341\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.3966 - accuracy: 0.8357\n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3966 - accuracy: 0.8352\n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3961 - accuracy: 0.8360\n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3965 - accuracy: 0.8347\n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.3964 - accuracy: 0.8357\n",
      "Epoch 80/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3958 - accuracy: 0.8353\n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3958 - accuracy: 0.8353\n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3956 - accuracy: 0.8353\n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3956 - accuracy: 0.8353\n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3960 - accuracy: 0.8361\n",
      "Epoch 85/100\n",
      "7500/7500 [==============================] - 1s 89us/step - loss: 0.3961 - accuracy: 0.8356\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3958 - accuracy: 0.8347\n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3952 - accuracy: 0.8355\n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.3956 - accuracy: 0.8345\n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3952 - accuracy: 0.8353\n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.3962 - accuracy: 0.8341\n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3960 - accuracy: 0.8365\n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3958 - accuracy: 0.8343\n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3954 - accuracy: 0.8357\n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3950 - accuracy: 0.8364\n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 1s 88us/step - loss: 0.3957 - accuracy: 0.8360\n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3953 - accuracy: 0.8355\n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3954 - accuracy: 0.8356\n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3958 - accuracy: 0.8357\n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3951 - accuracy: 0.8376\n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3955 - accuracy: 0.8356\n",
      "accuracy is 0.8432\n",
      "precision is 0.7489361702127659\n",
      "recall is 0.34577603143418467\n"
     ]
    }
   ],
   "source": [
    "# Fitting classifier to the Training set\n",
    "# Create your classifier here\n",
    "import keras\n",
    "\n",
    "#sequential model to initialize the neural networks and dense module to build the layers for NN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\"\"\"\n",
    "# two ways to build a deep learning model\n",
    "# 1. defining sequence of layers for NN\n",
    "# 2. Or Defining the layers in the form of Graph\n",
    "\"\"\"\n",
    "\n",
    "#initializing the ANN\n",
    "cls = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "# adding the first layer, and input layers also our first hidden layer\n",
    "# output_dim - number of nodes in the layer, can be average of input and output dim\n",
    "# init - weigts to be initilized\n",
    "# activation - activtion function you want to use in the layer\n",
    "\"\"\"\n",
    "\n",
    "# adding input and first hidden layer\n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu',input_dim = 11))\n",
    "\n",
    "# adding second hidden layer\n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n",
    "\n",
    "# adding third hidden layer\n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n",
    "\n",
    "\n",
    "# adding output layer\n",
    "\"\"\"\n",
    "if we have more than one dependent variables, \n",
    "whihc might be the case when we do one hot encoding for multi class dependent variable.\n",
    "We should pick the out_dim based on number of varibales we have and our activation will be 'softmax'\n",
    "\"\"\"\n",
    "cls.add(Dense(output_dim = 1,init = 'uniform',activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# compiling the ANN\n",
    "\"\"\"\n",
    "optimizer = algorithm to optimize for the weights (GD,SGD,MGD)\n",
    "            adam is one of the SGD available\n",
    "loss = algorithm used to calculate the cost or loss between the actual vs predicted\n",
    "        log loss is used for binary classification (binary_crossentropy for binary)\n",
    "metrics = metric used to evaluate your model\n",
    "\"\"\"\n",
    "cls.compile(optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "# fitting the ANN on our training data\n",
    "\"\"\"\n",
    "X - your training independent varibales data\n",
    "y - your training dependent varibal data\n",
    "batch_size - decides whether we are doing the GD, SD or MGD\n",
    "nb_epochs - number of times the \n",
    "\"\"\"\n",
    "cls.fit(X_train,y_train,batch_size = 10,nb_epoch = 100)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def get_confMatrix(y_pred,y_test,threshold):\n",
    "    y_pred = [1 if y >=threshold else 0 for y in y_pred] \n",
    "    # Making the Confusion Matrix\n",
    "    return confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = cls.predict(X_test)\n",
    "\n",
    "cm = get_confMatrix(y_pred,y_test,0.5)\n",
    "\n",
    "print(\"accuracy is {}\".format((cm[0,0]+cm[1,1])/len(y_test)))\n",
    "print(\"precision is {}\".format((cm[1,1])/(cm[1,1]+cm[0,1])))\n",
    "print(\"recall is {}\".format((cm[1,1])/(cm[1,0]+cm[1,1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K fold Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Cross validation mean and variance score is 83.72%,1.27% respectively\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\"\"\"\n",
    "The keras wrappers lib has scikit_learn cross validation function in the form of kerasClassifier\n",
    "kerasClassfier takes in a functions as input, whihc is nothing but your ANN classfier layers in the form of a function\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def build_churn_classifier():\n",
    "    cls = Sequential()\n",
    "    cls.add(Dense(output_dim = 6, init = 'uniform',activation = 'relu',input_dim = 11))\n",
    "    cls.add(Dense(output_dim = 6, init = 'uniform',activation = 'relu'))\n",
    "    cls.add(Dense(output_dim = 1, init = 'uniform',activation = 'sigmoid'))\n",
    "    cls.compile(optimizer = 'adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "    return cls\n",
    "cls = KerasClassifier(build_fn = build_churn_classifier,batch_size = 10,epochs = 100)\n",
    "cv_scores = cross_val_score(cls,X = X_train,y = y_train,cv = 10,n_jobs = -1)\n",
    "\n",
    "print(\"Our Cross validation mean and variance score is {}%,{}% respectively\".format(\n",
    "                                                                                np.round(cv_scores.mean()*100,2),\n",
    "                                                                                np.round(cv_scores.std()*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout regularization -- to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  app.launch_new_instance()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 0.5012 - accuracy: 0.7950\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4481 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.4417 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4434 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4343 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.4351 - accuracy: 0.7960\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.4345 - accuracy: 0.7960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.4356 - accuracy: 0.7960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.4317 - accuracy: 0.7960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 98us/step - loss: 0.4328 - accuracy: 0.7960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.4310 - accuracy: 0.7960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4341 - accuracy: 0.7960\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4323 - accuracy: 0.7960\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4340 - accuracy: 0.7960\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4339 - accuracy: 0.7960\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4342 - accuracy: 0.7960\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4288 - accuracy: 0.7960\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4342 - accuracy: 0.7960\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4326 - accuracy: 0.7960\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4305 - accuracy: 0.7960\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4311 - accuracy: 0.7960\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4330 - accuracy: 0.7960\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4321 - accuracy: 0.7960\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4272 - accuracy: 0.7960\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4321 - accuracy: 0.8083\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4299 - accuracy: 0.8080\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4309 - accuracy: 0.8151\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4302 - accuracy: 0.8138\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4271 - accuracy: 0.8140\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4316 - accuracy: 0.8161\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4287 - accuracy: 0.8175\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4324 - accuracy: 0.8005\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4278 - accuracy: 0.8136\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4299 - accuracy: 0.8023\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4285 - accuracy: 0.8101\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4265 - accuracy: 0.8261\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4305 - accuracy: 0.8198\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4282 - accuracy: 0.8249\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4289 - accuracy: 0.8248\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4296 - accuracy: 0.8256\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4284 - accuracy: 0.8256\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4308 - accuracy: 0.8274\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4286 - accuracy: 0.8267\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4305 - accuracy: 0.8246\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4336 - accuracy: 0.8101\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4307 - accuracy: 0.7960\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4279 - accuracy: 0.7968\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4305 - accuracy: 0.8030\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4315 - accuracy: 0.8037\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4316 - accuracy: 0.7960\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4309 - accuracy: 0.7960\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4277 - accuracy: 0.7983\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4269 - accuracy: 0.7960\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4301 - accuracy: 0.8164\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4274 - accuracy: 0.8171\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4287 - accuracy: 0.8180\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4290 - accuracy: 0.8142\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4317 - accuracy: 0.8241\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4297 - accuracy: 0.8142\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4318 - accuracy: 0.8080\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4298 - accuracy: 0.8156\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4260 - accuracy: 0.8100\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4290 - accuracy: 0.8224\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4281 - accuracy: 0.8250\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4263 - accuracy: 0.8251\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4289 - accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4263 - accuracy: 0.8271\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4291 - accuracy: 0.8296\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4300 - accuracy: 0.8305\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4296 - accuracy: 0.8275\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4306 - accuracy: 0.8229\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4286 - accuracy: 0.8198\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4300 - accuracy: 0.8198\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4278 - accuracy: 0.8206\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4308 - accuracy: 0.8284\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4296 - accuracy: 0.8123\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4294 - accuracy: 0.8141\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4270 - accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4299 - accuracy: 0.8161\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.4268 - accuracy: 0.8246\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4321 - accuracy: 0.8170\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4282 - accuracy: 0.8020\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4276 - accuracy: 0.8192\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4257 - accuracy: 0.8286\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.4303 - accuracy: 0.8220\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4259 - accuracy: 0.8189\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4269 - accuracy: 0.8204\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4315 - accuracy: 0.8242\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4271 - accuracy: 0.8251\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4282 - accuracy: 0.8229\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4272 - accuracy: 0.8210\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4284 - accuracy: 0.8184\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4259 - accuracy: 0.8286\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4328 - accuracy: 0.8062\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4267 - accuracy: 0.8166\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4292 - accuracy: 0.8264\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.4264 - accuracy: 0.8254\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4274 - accuracy: 0.8254\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4287 - accuracy: 0.8236\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4259 - accuracy: 0.8232\n",
      "accuracy is 0.833\n",
      "precision is 0.75177304964539\n",
      "recall is 0.2617283950617284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "In dropout regularization in every iteration randomly some of the neurons are randomly disabled,\n",
    "so that our ANN is not over relying on a particular neuron, this will make sure of two things\n",
    "1. Every neuron is independently try to workout a relationship without relying on other \n",
    "2. Also We dont have a single configuration at every itteration \n",
    "which will make sure overfitting is avoided\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#initializing the ANN\n",
    "cls = Sequential()\n",
    "\n",
    "# adding input and first hidden layer without dropout function for disabling \n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu',input_dim = 11))\n",
    "cls.add(Dropout(p=0.1))\n",
    "\n",
    "\n",
    "# adding second hidden layer with dropout fn\n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n",
    "cls.add(Dropout(p=0.1))\n",
    "\n",
    "# adding third hidden layer with dropout function\n",
    "cls.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n",
    "cls.add(Dropout(p=0.1))\n",
    "\n",
    "# adding output layer\n",
    "cls.add(Dense(output_dim = 1,init = 'uniform',activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# compiling the ANN\n",
    "cls.compile(optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "# fitting the ANN on our training data\n",
    "cls.fit(X_train,y_train,batch_size = 10,nb_epoch = 100)\n",
    "\n",
    "def get_confMatrix(y_pred,y_test,threshold):\n",
    "    y_pred = [1 if y >=threshold else 0 for y in y_pred] \n",
    "    # Making the Confusion Matrix\n",
    "    return confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = cls.predict(X_test)\n",
    "\n",
    "cm = get_confMatrix(y_pred,y_test,0.5)\n",
    "\n",
    "print(\"accuracy is {}\".format((cm[0,0]+cm[1,1])/len(y_test)))\n",
    "print(\"precision is {}\".format((cm[1,1])/(cm[1,1]+cm[0,1])))\n",
    "print(\"recall is {}\".format((cm[1,1])/(cm[1,0]+cm[1,1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
